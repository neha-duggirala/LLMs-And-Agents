{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Acd-FgUmDyP2"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "TlX8Cb-lD0-1"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "  {\n",
        "    \"question\": \"What is the purpose of the Vehicle class in this code?\",\n",
        "    \"answer\": \"The Vehicle class represents a vehicle entity and stores its id, name, and type.\",\n",
        "    \"code\": \"// Original Path: LLD-Questions-master/ParkingLot/ParkingLot/Entities/Vehicle.cs\\n\\n\\ufeffusing System;\\nusing System.Collections.Generic;\\nusing System.Linq;\\nusing System.Text;\\nusing System.Threading.Tasks;\\n\\nnamespace ParkingLot.Entities\\n{\\n    public class Vehicle\\n    {\\n        private readonly int id;\\n        public readonly string name;\\n        private readonly VehicleType type;\\n        public Vehicle(int id, string name, VehicleType type)\\n        {\\n            this.id = id;\\n            this.name = name;\\n            this.type = type;\\n        }\\n        public VehicleType GetType()\\n        {\\n            return type;\\n        }\\n        public string GetName()\\n        {\\n            return name;\\n        }\\n\\n    }\\n}\\n\"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"What variables are stored as readonly in the Vehicle class?\",\n",
        "    \"answer\": \"The id and type variables are stored as readonly in the Vehicle class.\",\n",
        "    \"code\": \"// Original Path: LLD-Questions-master/ParkingLot/ParkingLot/Entities/Vehicle.cs\\n\\n\\ufeffusing System;\\nusing System.Collections.Generic;\\nusing System.Linq;\\nusing System.Text;\\nusing System.Threading.Tasks;\\n\\nnamespace ParkingLot.Entities\\n{\\n    public class Vehicle\\n    {\\n        private readonly int id;\\n        public readonly string name;\\n        private readonly VehicleType type;\\n        public Vehicle(int id, string name, VehicleType type)\\n        {\\n            this.id = id;\\n            this.name = name;\\n            this.type = type;\\n        }\\n        public VehicleType GetType()\\n        {\\n            return type;\\n        }\\n        public string GetName()\\n        {\\n            return name;\\n        }\\n\\n    }\\n}\\n\"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"What is the purpose of the GetType method in the Vehicle class?\",\n",
        "    \"answer\": \"The GetType method returns the type of the vehicle.\",\n",
        "    \"code\": \"// Original Path: LLD-Questions-master/ParkingLot/ParkingLot/Entities/Vehicle.cs\\n\\n\\ufeffusing System;\\nusing System.Collections.Generic;\\nusing System.Linq;\\nusing System.Text;\\nusing System.Threading.Tasks;\\n\\nnamespace ParkingLot.Entities\\n{\\n    public class Vehicle\\n    {\\n        private readonly int id;\\n        public readonly string name;\\n        private readonly VehicleType type;\\n        public Vehicle(int id, string name, VehicleType type)\\n        {\\n            this.id = id;\\n            this.name = name;\\n            this.type = type;\\n        }\\n        public VehicleType GetType()\\n        {\\n            return type;\\n        }\\n        public string GetName()\\n        {\\n            return name;\\n        }\\n\\n    }\\n}\\n\"\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eox_FiFLDy0V"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    {\n",
        "        \"question\": \"CODE \\n\" + example[\"code\"] + \"QUESTION \\n\" + example[\"question\"],\n",
        "        \"answer\": example[\"answer\"]\n",
        "    }\n",
        "    for example in data\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "e4dVR8IyD3Cs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Convert to Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_list(questions)\n",
        "\n",
        "# Combine into a DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "doNJGBVVD5Mz"
      },
      "outputs": [],
      "source": [
        "model_name = \"microsoft/codebert-base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "D5SJhkd-D7SJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Bk-KjxlSD8wR"
      },
      "outputs": [],
      "source": [
        "# create tokenize function\n",
        "def tokenize_function(examples):\n",
        "    print(examples)\n",
        "    # extract text\n",
        "    text = examples[\"question\"]\n",
        "\n",
        "    #tokenize and truncate text\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "5e50aabb4d5f44cab652c97c2299bab0",
            "c5c9d2bfb6a0434c9115e888156dc874",
            "909034f04d2342d69fa17a519f159c8e",
            "7011c812f6e94a6e8f294b08285fe166",
            "168c443db5e04a1dbe6e161324877ef9",
            "e2a3e9dcd5d045e79f199c4d87195e22",
            "e21c595076df4f7c9dd7bc5b86363e77",
            "50fda80d5c234c7cbd4f542c245ace26",
            "700c445ee90945a1b28566c5f2c1a59c",
            "55b1fdb327764945bc495b7060459c37",
            "2bb34895257f402182da9f9da734f955"
          ]
        },
        "id": "nWsJL6XcD-CR",
        "outputId": "216b4745-0dec-4ead-824d-8b23877c94ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e50aabb4d5f44cab652c97c2299bab0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'overflow_to_sample_mapping', 'start_positions', 'end_positions'],\n",
              "        num_rows: 3\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenize training and validation datasets\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "JpNAR867PTT1"
      },
      "outputs": [],
      "source": [
        "# create tokenize function\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the question and code context\n",
        "    # Since the data is structured as \"CODE \\n code \\n QUESTION \\n question\",\n",
        "    # we can tokenize the whole string.\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        truncation=\"only_first\", # Truncate only the first sequence if it's too long\n",
        "        max_length=512,\n",
        "        padding=\"max_length\", # Pad to max_length\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True, # Needed for finding answer start/end positions\n",
        "    )\n",
        "\n",
        "    # The model expects 'start_positions' and 'end_positions' for training.\n",
        "    # We need to find these positions based on the original answer text.\n",
        "    # This is a simplified approach for demonstration. A more robust\n",
        "    # implementation would handle cases where the answer is not found or\n",
        "    # split across chunks due to truncation/overflowing tokens.\n",
        "\n",
        "    # Initialize lists for labels\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i in range(len(examples[\"answer\"])):\n",
        "        answer = examples[\"answer\"][i]\n",
        "        # Find the start and end character index of the answer in the original question string\n",
        "        # Note: This assumes the answer is directly present in the 'question' string,\n",
        "        # which is constructed as CODE + code + QUESTION + question.\n",
        "        # A more robust solution would find the answer within the 'code' or 'question' part specifically.\n",
        "        context = examples[\"question\"][i] # Use the full text as context for finding the answer\n",
        "\n",
        "        # Find the character start and end index of the answer in the context\n",
        "        start_char = context.find(answer)\n",
        "        end_char = start_char + len(answer)\n",
        "\n",
        "        # If the answer is not found, set positions to 0 (or a value indicating no answer)\n",
        "        if start_char == -1:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Convert character indices to token indices\n",
        "            # Use offset mapping to find the corresponding token indices\n",
        "            offset_mapping = tokenized_inputs[\"offset_mapping\"][i]\n",
        "\n",
        "            start_token = 0\n",
        "            end_token = 0\n",
        "\n",
        "            # Find the token containing the start character\n",
        "            for token_index, (start, end) in enumerate(offset_mapping):\n",
        "                 if start_char >= start and start_char < end:\n",
        "                    start_token = token_index\n",
        "                    break\n",
        "\n",
        "            # Find the token containing the end character\n",
        "            for token_index, (start, end) in enumerate(offset_mapping):\n",
        "                 if end_char > start and end_char <= end:\n",
        "                    end_token = token_index\n",
        "                    break\n",
        "\n",
        "            start_positions.append(start_token)\n",
        "            end_positions.append(end_token)\n",
        "\n",
        "\n",
        "    tokenized_inputs[\"start_positions\"] = start_positions\n",
        "    tokenized_inputs[\"end_positions\"] = end_positions\n",
        "\n",
        "    # Remove the offset_mapping as it's not needed for training\n",
        "    del tokenized_inputs[\"offset_mapping\"]\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As0BDZ93PYAD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIxwgUuaFWjX",
        "outputId": "f5f2187f-0c2f-4889-fe2c-efade2120c52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBbzijRqGZJ0"
      },
      "source": [
        "# Testing untrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0yM_zpE0Of",
        "outputId": "19db9978-fb76-42cf-aecf-d0a7290fae35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'score': 2.516050881240517e-05, 'start': 21, 'end': 22, 'answer': '-'}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "# Define the question you want to ask\n",
        "new_question_text = \"What is the purpose of the GetName method in the Vehicle class?\"\n",
        "code_context = \"\"\"// Original Path: LLD-Questions-master/ParkingLot/ParkingLot/Entities/Vehicle.cs\n",
        "\n",
        "\\ufeffusing System;\n",
        "using System.Collections.Generic;\n",
        "using System.Linq;\n",
        "using System.Text;\n",
        "using System.Threading.Tasks;\n",
        "\n",
        "namespace ParkingLot.Entities\n",
        "{\n",
        "    public class Vehicle\n",
        "    {\n",
        "        private readonly int id;\n",
        "        public readonly string name;\n",
        "        private readonly VehicleType type;\n",
        "        public Vehicle(int id, string name, VehicleType type)\n",
        "        {\n",
        "            this.id = id;\n",
        "            this.name = name;\n",
        "            this.type = type;\n",
        "        }\n",
        "        public VehicleType GetType()\n",
        "        {\n",
        "            return type;\n",
        "        }\n",
        "        public string GetName()\n",
        "        {\n",
        "            return name;\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Create a question-answering pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Get the answer using the pipeline\n",
        "answer = qa_pipeline(question=new_question_text, context=code_context)\n",
        "\n",
        "# Print the answer\n",
        "answer\n",
        "\n",
        "# Note: The output format of the answer depends on the pipeline and the model's capabilities.\n",
        "# For a 'question-answering' pipeline, it typically returns a dictionary with the 'answer',\n",
        "# 'start', 'end', and 'score'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "c4wYmJBQFJGf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deoM7SGvGtmg"
      },
      "source": [
        "# Fine tuning using LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "tHsxSLd6Gv3F"
      },
      "outputs": [],
      "source": [
        "\n",
        "peft_config = LoraConfig(task_type=\"QUESTION_ANS\",\n",
        "                        r=2,\n",
        "                        lora_alpha=32,\n",
        "                        lora_dropout=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUJeJRJkHCVw",
        "outputId": "e391a965-7ad7-4b67-9a3c-0de7b8621e99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LoraConfig(task_type='QUESTION_ANS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=2, target_modules=None, exclude_modules=None, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhV05LhqHEEf",
        "outputId": "a7e1e968-bb35-44e7-ebc4-3b4c59d7aeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 75,266 || all params: 124,131,844 || trainable%: 0.0606\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "t14ml_XgHG8S"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "oiBNphDeOhzL"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= model_name + \"-lora-qa\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "BqYRknneOo2k",
        "outputId": "b30e7277-96dd-4f5f-c54a-9b37f45dd865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-68-67f6b9daea7c>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 02:59, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10, training_loss=3.841696929931641, metrics={'train_runtime': 201.4189, 'train_samples_per_second': 0.149, 'train_steps_per_second': 0.05, 'total_flos': 7845839216640.0, 'train_loss': 3.841696929931641, 'epoch': 10.0})"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creater trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        ")\n",
        "\n",
        "# train model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEYiCPNyQPoR",
        "outputId": "18d7a7ea-8e67-4943-d950-a027bee448be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForQuestionAnswering(\n",
              "  (base_model): LoraModel(\n",
              "    (model): RobertaForQuestionAnswering(\n",
              "      (roberta): RobertaModel(\n",
              "        (embeddings): RobertaEmbeddings(\n",
              "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "          (token_type_embeddings): Embedding(1, 768)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): RobertaEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSdpaSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=2, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=2, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=2, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=2, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (qa_outputs): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-g4RqiJO3W2",
        "outputId": "cd40ce0d-1770-40df-a166-e5c858033ea2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'score': 3.368990292074159e-05, 'start': 144, 'end': 148, 'answer': 'Linq'}"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Get the answer using the pipeline\n",
        "answer = qa_pipeline(question=new_question_text, context=code_context)\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZmR5J46wQSbY",
        "outputId": "617001d1-434b-4a32-eba1-3dd13b1a03e3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What is the purpose of the GetName method in the Vehicle class?'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_question_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFFOYuvgQWS1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "168c443db5e04a1dbe6e161324877ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb34895257f402182da9f9da734f955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50fda80d5c234c7cbd4f542c245ace26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b1fdb327764945bc495b7060459c37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e50aabb4d5f44cab652c97c2299bab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5c9d2bfb6a0434c9115e888156dc874",
              "IPY_MODEL_909034f04d2342d69fa17a519f159c8e",
              "IPY_MODEL_7011c812f6e94a6e8f294b08285fe166"
            ],
            "layout": "IPY_MODEL_168c443db5e04a1dbe6e161324877ef9"
          }
        },
        "700c445ee90945a1b28566c5f2c1a59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7011c812f6e94a6e8f294b08285fe166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b1fdb327764945bc495b7060459c37",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb34895257f402182da9f9da734f955",
            "value": " 3/3 [00:00&lt;00:00, 36.15 examples/s]"
          }
        },
        "909034f04d2342d69fa17a519f159c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50fda80d5c234c7cbd4f542c245ace26",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_700c445ee90945a1b28566c5f2c1a59c",
            "value": 3
          }
        },
        "c5c9d2bfb6a0434c9115e888156dc874": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2a3e9dcd5d045e79f199c4d87195e22",
            "placeholder": "​",
            "style": "IPY_MODEL_e21c595076df4f7c9dd7bc5b86363e77",
            "value": "Map: 100%"
          }
        },
        "e21c595076df4f7c9dd7bc5b86363e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2a3e9dcd5d045e79f199c4d87195e22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
